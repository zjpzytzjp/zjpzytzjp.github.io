<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://zjpzytzjp.github.io/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zjpzytzjp.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-redis" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/10/redis/" class="article-date">
  <time class="dt-published" datetime="2023-08-10T03:27:38.154Z" itemprop="datePublished">2023-08-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h3 id="redis为什么这么快"><a href="#redis为什么这么快" class="headerlink" title="redis为什么这么快"></a>redis为什么这么快</h3><p>一方面是因为它是内存数据库，所有操作都在内存中实现，内存的访问速度非常快。</p>
<p>另一方面，归功于它的数据结构，高效的数据结构是redis快速处理数据的基础</p>
<h3 id="redis有哪些数据类型"><a href="#redis有哪些数据类型" class="headerlink" title="redis有哪些数据类型"></a>redis有哪些数据类型</h3><p>redis有string，list，hash，sorted set，set类型，其中除了string外都是集合数据类型，一个键对应了一个集合</p>
<p>它们的底层实现如下：</p>
<p><img src="https://static001.geekbang.org/resource/image/82/01/8219f7yy651e566d47cc9f661b399f01.jpg?wh=4000*1188" alt="img"></p>
<h3 id="键和值之间使用的是什么结构组织"><a href="#键和值之间使用的是什么结构组织" class="headerlink" title="键和值之间使用的是什么结构组织"></a>键和值之间使用的是什么结构组织</h3><p>键和值之间是使用的哈希表的形式组织起来的，使用了一个哈希表来保存所有的键值对。我们也称它为全局哈希表。</p>
<p>那么既然除string类型的四种数据类型的值是集合，那么本质是数组的哈希表是如何来存储他们的呢？</p>
<p>其实数组的每个元素都是一个哈希桶，它保存的是两个指针，一个指向实际的键和值，这样一来，即使值是一个集合，也可以通过指针找到。</p>
<p>这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。也就是说，不管哈希表里有 10 万个键还是 100 万个键，我们只需要一次计算就能找到相应的键。</p>
<h3 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h3><p>哈希冲突就是有一些 key 的哈希值对应到了同一个哈希桶中</p>
<p>解决方法：链式哈希，也就是同一个哈希桶的元素按照链表存储，它们之间用指针来链接。</p>
<p>问题：链表必须要通过指针逐一查找，效率低，速度慢，因此要避免过长的链表</p>
<p>解决方案：rehash操作，也就是增加现有的哈希桶数量</p>
<h3 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h3><p>redis默认使用两个全局哈希表，哈希表1和哈希表2。</p>
<p>步骤：</p>
<p>1.将哈希表2的容量扩容，比如扩容成哈希表1的两倍</p>
<p>2.将哈希表1的数据重新映射拷贝到哈希表2中</p>
<p>3.释放哈希表1的空间</p>
<p>但是这其中的第二个步骤涉及到大量的拷贝操作，如果redis一次性进行所以拷贝操作会线程阻塞，无法服务其他请求。因此采用了渐进式rehash。</p>
<p>简单说就是在拷贝数据的时候正常处理请求，每处理一个请求，就从哈希表1的第一个索引开始，顺带把这个索引位置下的所有entry拷贝到哈希表2中去，第二个请求就从哈希表1的下一个索引开始拷贝。这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p>
<h3 id="有哪些底层数据结构"><a href="#有哪些底层数据结构" class="headerlink" title="有哪些底层数据结构"></a>有哪些底层数据结构</h3><p>整数数组、双向链表、哈希表、压缩列表和跳表。</p>
<p>压缩列表：实际是一个数组，和数组不同的是压缩列表有zlbyte，zltail，zllen三个字段，分别表示，列表长度，列表偏移量，列表中entry的个数。表尾还有一个zlend</p>
<p>压缩列表定位第一个元素和最后一个元素可以通过三个字段直接定位，复杂度为O（1）。</p>
<p>跳表：跳表在链表的基础上加上了多级索引，通过索引位置的几次跳转来实现数据的快速定位。</p>
<img src="https://static001.geekbang.org/resource/image/1e/b4/1eca7135d38de2yy16681c2bbc4f3fb4.jpg?wh=1878*1126" alt="img" style="zoom: 33%;" />

<p>当数据量很大时，跳表的查找复杂度就是 O(logN)</p>
<h3 id="整数数组和压缩列表在查找时间复杂度上不占优势，为什么redis仍然使用"><a href="#整数数组和压缩列表在查找时间复杂度上不占优势，为什么redis仍然使用" class="headerlink" title="整数数组和压缩列表在查找时间复杂度上不占优势，为什么redis仍然使用"></a>整数数组和压缩列表在查找时间复杂度上不占优势，为什么redis仍然使用</h3><p>1、内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。</p>
<p> 2、数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</p>
<h3 id="Redis的单线程"><a href="#Redis的单线程" class="headerlink" title="Redis的单线程"></a>Redis的单线程</h3><p>redis的单线程主要指的是网络IO 和键值对读写的时候是由一个线程完成的。但其实redis的持久化，异步删除，集群数据同步等操作是由额外的线程来执行的。</p>
<p>为什么用单线程：</p>
<p>首先要知道多线程的开销，多线程编程模式面临共享资源的并发访问控制问题。</p>
<h3 id="单线程redis为什么会这么快"><a href="#单线程redis为什么会这么快" class="headerlink" title="单线程redis为什么会这么快"></a>单线程redis为什么会这么快</h3><p>一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。</p>
<p>另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p>
<h3 id="基于多路复用的高性能IO模型"><a href="#基于多路复用的高性能IO模型" class="headerlink" title="基于多路复用的高性能IO模型"></a>基于多路复用的高性能IO模型</h3><p>在redis只运行单个线程的情况下，该机制允许内核同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字的链接情况和数据情况，一旦有请求到达，立马通知redis线程处理，这就实现了redis单线程同时处理多个IO流的效果。</p>
<img src="https://static001.geekbang.org/resource/image/00/ea/00ff790d4f6225aaeeebba34a71d8bea.jpg?wh=3472*2250" alt="img" style="zoom: 25%;" />



<p>为了保证请求到达时，可以及时通知redis线程，select&#x2F;epoll提供了事件回调机制，即针对不同事件的发生，调用相应的处理函数。</p>
<p>回调机制：select&#x2F;epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放入一个事件队列，redis单线程对该事件队列不断进行处理，并且调用对应事件回调函数。</p>
<h3 id="redis的持久化"><a href="#redis的持久化" class="headerlink" title="redis的持久化"></a>redis的持久化</h3><h4 id="AOF机制"><a href="#AOF机制" class="headerlink" title="AOF机制"></a>AOF机制</h4><h4 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h4><p>redis先执行命令，把数据写入内存，然后才记录日志。AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。</p>
<h4 id="好处："><a href="#好处：" class="headerlink" title="好处："></a>好处：</h4><p>避免出现记录错误命令的情况。它是在命令执行后才记录日志，所以不会阻塞当前的写操作。</p>
<h4 id="风险："><a href="#风险：" class="headerlink" title="风险："></a>风险：</h4><p>如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。</p>
<p>​				其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。</p>
<h4 id="写回策略："><a href="#写回策略：" class="headerlink" title="写回策略："></a>写回策略：</h4><p>​				Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</p>
<p>​				Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲				区中的内容写入磁盘；</p>
<p>​				No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系				统决定何时将缓冲区内容写回磁盘。</p>
<p><img src="https://static001.geekbang.org/resource/image/72/f8/72f547f18dbac788c7d11yy167d7ebf8.jpg?wh=2284*682" alt="img"></p>
<h4 id="AOF文件过大导致的问题："><a href="#AOF文件过大导致的问题：" class="headerlink" title="AOF文件过大导致的问题："></a>AOF文件过大导致的问题：</h4><p>一是，文件系统本身对文件大小有限制，无法保存过大的文件；</p>
<p>二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；</p>
<p>三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。</p>
<h4 id="因此需要AOF重写日志的出现"><a href="#因此需要AOF重写日志的出现" class="headerlink" title="因此需要AOF重写日志的出现"></a>因此需要AOF重写日志的出现</h4><p>：就是在redis重写时，根据数据库中现有的键值对创建一个新的AOF文件，每一个键值对都用一个命令来存储。由于AOF文件是追加记录的，可能某一个键值对被多次修改，重写日志只保留它的最新状态，这样大大降低了AOF的大小</p>
<p><img src="https://static001.geekbang.org/resource/image/65/08/6528c699fdcf40b404af57040bb8d208.jpg?wh=4000*1088" alt="img"></p>
<h4 id="重写会阻塞主线程吗？"><a href="#重写会阻塞主线程吗？" class="headerlink" title="重写会阻塞主线程吗？"></a>重写会阻塞主线程吗？</h4><p>不会，重写是在子线程中进行的，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>
<h3 id="内存快照"><a href="#内存快照" class="headerlink" title="内存快照"></a>内存快照</h3><h4 id="定义：-1"><a href="#定义：-1" class="headerlink" title="定义："></a>定义：</h4><p>内存中的数据某一刻的状态记录。对redis来说，就是把某一时刻的状态以文件的形式存入磁盘，RDB记录的是数据，不是AOF的命令，所以数据恢复起来很快。</p>
<h4 id="给哪些数据做快照"><a href="#给哪些数据做快照" class="headerlink" title="给哪些数据做快照"></a>给哪些数据做快照</h4><p>做的是全量快照，也就是内存中的所有数据。redis默认做快照是用bgsave，它会创建一个子进程，所以不会阻塞主线程。</p>
<h4 id="快照时数据能修改吗"><a href="#快照时数据能修改吗" class="headerlink" title="快照时数据能修改吗"></a>快照时数据能修改吗</h4><p>为了避免快照导致的不能写操作的情况，redis采用了操作系统的写时复制技术。</p>
<p>即如果快照时要修改数据则把那个数据做个复制，在数据副本上进行修改，而子进程继续进行快照的存储。</p>
<p><img src="https://static001.geekbang.org/resource/image/a2/58/a2e5a3571e200cb771ed8a1cd14d5558.jpg?wh=13333*7500" alt="img"></p>
<h4 id="多久做一次快照"><a href="#多久做一次快照" class="headerlink" title="多久做一次快照"></a>多久做一次快照</h4><p>快照间隔越短对数据恢复越好，但是如果频繁地执行全量快照，也会带来两方面的开销。</p>
<p>一方面，大量数据写入磁盘，给磁盘带来很大的压力。</p>
<p>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。</p>
<p>如何解决：做增量快照，即后续的快照只对修改的数据进行快照记录，这样就可以避免每次全量快照带来的开销。</p>
<p>但是为了达到“记住哪些数据被修改的效果”也需要消耗很多资源。</p>
<p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p>
<p>这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>
<h3 id="主从库"><a href="#主从库" class="headerlink" title="主从库"></a>主从库</h3><h4 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h4><p>redis采用主从库模式的方式来保证数据一致性，主从库采用的是读写分离方式</p>
<p>读操作：主库和从库都可以进行读操作</p>
<p>写操作：首先在主库操作，再将数据同步给从库</p>
<h4 id="为何读写分离"><a href="#为何读写分离" class="headerlink" title="为何读写分离"></a>为何读写分离</h4><p>如果客户端对同一个数据修改了三次，每次修改请求都被分发给了不同的库，那么这三个库中的数据就不一致了，读取这个数据的时候就有可能读取到旧的值。</p>
<h4 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h4><p>首先，从库发送指令给主库，请求同步，主库接收到请求后，生成一个RDB文件，并且把所有数据都存进去，如何发给从库，从库接收到数据后，会把自己当下的数据清空，如何再装入主库来的数据。在主库把数据传给从库的过程中，主库不会阻塞，仍然在接受请求，但这些请求中的写操作并没有同步到刚刚的RDB文件中，所以redis在内存中专门的replication buffer中记录的修改发送给从库，从库再执行这些修改，达到同步。</p>
<h4 id="主从级联"><a href="#主从级联" class="headerlink" title="主从级联"></a>主从级联</h4><p>在进行数据同步时，主库进行了两个非常耗时的操作，生成RDB文件和传输RDB文件</p>
<p>为了分担主库的压力，可以采用主-从-从的方式来，将主库生成RDB和传输RDB的工作级联给从库来执行。</p>
<p>简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。</p>
<p><img src="https://static001.geekbang.org/resource/image/40/45/403c2ab725dca8d44439f8994959af45.jpg?wh=3543*1791" alt="img"></p>
<h4 id="主从库之间网络断连了怎么办"><a href="#主从库之间网络断连了怎么办" class="headerlink" title="主从库之间网络断连了怎么办"></a>主从库之间网络断连了怎么办</h4><p>在主从库完成全量复制之后，主从库之间就会维护一个网络连接，通过这个连接把后续的操作发给从库，避免了频繁建立连接的开销，但是却有了网络断联和阻塞的问题</p>
<p>采用增量复制的方式来实现同步，其中使用了repl-backlog-buffer缓冲区。</p>
<p>这个缓冲区是环形缓冲区，主库写入，从库读取，这样的操作流程，在发生网络断联的时候，主库继续在写入，则主库写入进度比从库读取进度要快，网络连接恢复的时候，从库发出请求，并且把自己读取到了哪里的位置发给主库，主库判断从库读取到的位置，然后和自己写入的位置进行比较，把这两者之间的数据发送给从库。</p>
<p>由于是环形缓冲区，如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。</p>
<ol>
<li>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。 </li>
<li>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。</li>
</ol>
<p>解决这个问题我们可以调高缓冲区的大小或者切片集群。</p>
<h3 id="哨兵机制"><a href="#哨兵机制" class="headerlink" title="哨兵机制"></a>哨兵机制</h3><p>如果主库挂了，那我们就需要一个新的主库，比如把一个从库变成新的主库，这涉及到三个问题</p>
<p>1.主库真的挂了吗</p>
<p>2.谁来当新主库</p>
<p>3.怎么把新主库的相关信息通知给从库和客户端</p>
<h4 id="定义：-2"><a href="#定义：-2" class="headerlink" title="定义："></a>定义：</h4><p>哨兵就是运行在redis上的一个进程，它有三个任务，监控，选主，通知</p>
<h4 id="监控："><a href="#监控：" class="headerlink" title="监控："></a>监控：</h4><p>哨兵在运行时会周期性的给所有的主从库发送ping命令，检测它是否是在线状态，如果从库没有响应，哨兵就会判定他是下线状态，主库如果不响应，就会判断主库下线，开始自动转换主库的流程</p>
<h4 id="选主："><a href="#选主：" class="headerlink" title="选主："></a>选主：</h4><p>主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</p>
<h4 id="通知："><a href="#通知：" class="headerlink" title="通知："></a>通知：</h4><p>哨兵会把新主库的信息发送给其他从库，让它们和新主库建立连接，进行数据复制，同时通知客户端，以后的请求发给新主库</p>
<h4 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h4><p>哨兵在监控主库是否下线的时候可能受制于自己的网络问题等原因发生误判，也就是主库其实没有下线，但哨兵认为它下线开始了主从切换，主从切换过程资源消耗较大。</p>
<p>因此为了避免出现误判，引入了多实例组成的集群模式进行部署哨兵，多个哨兵一起判断这个主库是否下线了，避免单个哨兵网络不好的情况</p>
<p>主观下线就是某个哨兵认为主库下线了，客观下线是一定量的哨兵都认为主库下线了，主库才会被标记为客观下线</p>
<p>最好要有 N&#x2F;2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。（多少实例，管理员可以调）</p>
<p><img src="https://static001.geekbang.org/resource/image/19/0d/1945703abf16ee14e2f7559873e4e60d.jpg?wh=3807*1416" alt="img"></p>
<h4 id="如何选择新主库"><a href="#如何选择新主库" class="headerlink" title="如何选择新主库"></a>如何选择新主库</h4><p>选主库的过程主要是两个“筛选+打分”。</p>
<p><img src="https://static001.geekbang.org/resource/image/f2/4c/f2e9b8830db46d959daa6a39fbf4a14c.jpg?wh=3671*1743" alt="img"></p>
<p>筛选：筛选的条件主要是从库要在线，但是在选举时候从库在线不够有说服力，可能它过一会就下线了，所以除了检查从库的当前状态， 还要检查从库之前的网络状态，如果它经常和之前的主库断联说明它的网络状态不太好，不适合做新主库。这里有一个阈值判断，断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。</p>
<p>打分：</p>
<p>第一轮：优先级最高的从库得分最高</p>
<p>用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。</p>
<p>第二轮：和旧主库同步程度最接近的从库得分高。</p>
<p>这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。</p>
<p>我们想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库。</p>
<p>第三轮：ID号小的从库得分高</p>
<p>在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。</p>
<h4 id="基于pub-sub机制的哨兵集群组成"><a href="#基于pub-sub机制的哨兵集群组成" class="headerlink" title="基于pub&#x2F;sub机制的哨兵集群组成"></a>基于pub&#x2F;sub机制的哨兵集群组成</h4><p>pub&#x2F;sub机制就是发布订阅机制</p>
<p>部署哨兵集群的时候，配置哨兵时只设置了主库的信息，并没有给其他哨兵的连接信息，那么哨兵之间是如何连接上的呢？</p>
<p>哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。</p>
<p>除了哨兵实例，我们自己编写的应用程序也可以通过 Redis 进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。</p>
<p><img src="https://static001.geekbang.org/resource/image/ca/b1/ca42698128aa4c8a374efbc575ea22b1.jpg?wh=2822*1535" alt="img"></p>
<p>哨兵除了彼此要形成集群外，还需要和从库建立连接，方便监控</p>
<p>这是由哨兵向主库发送 INFO 命令来完成的。主库会把从库列表给哨兵</p>
<p><img src="https://static001.geekbang.org/resource/image/88/e0/88fdc68eb94c44efbdf7357260091de0.jpg?wh=2499*1404" alt="img"></p>
<p>但是，哨兵不能只和主、从库连接。因为，主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。</p>
<p>从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub&#x2F;sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。</p>
<h4 id="有哪个哨兵进行主从切换"><a href="#有哪个哨兵进行主从切换" class="headerlink" title="有哪个哨兵进行主从切换"></a>有哪个哨兵进行主从切换</h4><p>确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程。</p>
<p>客观下线的流程：</p>
<p>任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。</p>
<p><img src="https://static001.geekbang.org/resource/image/e0/84/e0832d432c14c98066a94e0ef86af384.jpg?wh=2322*1260" alt="img"></p>
<p>此时，这个哨兵就开始再给其他哨兵发送命令，希望自己来执行主从切换，并且让其他哨兵投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。</p>
<p>想成为leader，要满足两个条件：拿到半数以上的赞成票，且票数高于等于配置文件中的quorum值。</p>
<p><img src="https://static001.geekbang.org/resource/image/5f/d9/5f6ceeb9337e158cc759e23c0f375fd9.jpg?wh=2843*1934" alt="img"></p>
<p>如果 S3 没有拿到 2 票 Y，那么这轮投票就不会产生 Leader。哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2 倍），再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。</p>
<p>需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。这一点很重要，实际应用时可不能忽略了。</p>
<h3 id="切片集群"><a href="#切片集群" class="headerlink" title="切片集群"></a>切片集群</h3><h4 id="定义：-3"><a href="#定义：-3" class="headerlink" title="定义："></a>定义：</h4><p>分片集群，指启动多个Redis实例组成一个集群，然后按一定的规则把收到的划分成多份，每一份用一个实例来保存。</p>
<h4 id="数据切片和实例的对应分布关系"><a href="#数据切片和实例的对应分布关系" class="headerlink" title="数据切片和实例的对应分布关系"></a>数据切片和实例的对应分布关系</h4><p>在切片集群中，数据和实例是如何对应的呢？</p>
<p>Redis CLuster方案采用哈希槽的方式处理数据和实例的映射关系。</p>
<p>在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p>
<p>映射过程：首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</p>
<p>然后把这些槽平均分配给实例上，例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384&#x2F;N 个。</p>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>string类型提供了一个键对应一个值的保存形式，而且string可以保存二进制字节流，只要把数据转换成二进制字节数组就可以保存。</p>
<p>string类型并不是适合所有场景的，它有一个明显的短板，那就是它保存数据的时候所消耗的内存空间较多</p>
<h4 id="为什么string类型空间消耗大"><a href="#为什么string类型空间消耗大" class="headerlink" title="为什么string类型空间消耗大"></a>为什么string类型空间消耗大</h4><p>其实，除了记录实际数据之外，string还会记录数据长度，空间使用等信息，也被叫做元数据。</p>
<p>当保存的数据较小的时候，元数据的空间开销就会显得比较大。</p>
<p>String是如何保存数据的呢？</p>
<p>当你保存64位有符号整数时，String类型把它保存在一个8字节的Long类型整数，这种方式被称为int编码</p>
<p>当年保存的数据包含字符，就会采用简单动态字符串结构体来保存</p>
<p><img src="https://static001.geekbang.org/resource/image/37/57/37c6a8d5abd65906368e7c4a6b938657.jpg?wh=1926*1400" alt="img"></p>
<p>如图，会有四个字节保存数据长度，四个字节保存实际分配长度，buf才是保存实际数据的部分。</p>
<p>除此之外，对于String来说还有一个redisObject的结构体的开销。</p>
<p>因为redis数据类型很多，所以会有很多数据类型有相同元数据保存的情况出现（比如最后一次保存时间这种），所以redis采用redisObject的方式来存储这种元数据，并且指向实际数据。</p>
<p>一个RedisObject包含一个8字节的元数据和8字节的字节指针，字节指针指向具体数据类型的实际的数据所在，例如指向string的sds结构所在的内存地址。</p>
<p><img src="https://static001.geekbang.org/resource/image/34/57/3409948e9d3e8aa5cd7cafb9b66c2857.jpg?wh=2214*1656" alt="img"></p>
<p>为了节省空间，Redis对Long类型数据和SDS的内存布局做了优化。</p>
<p>一方面，保存的数据是long类型数据的话，RedisObject的指针就直接赋值给整数数据了，不会再用额外的指针，节省开销</p>
<p>另一方面，保存的是字符型数据的话，并且字符数据小于44个字节，就会把RedisObject的元数据，指针，SDS放在一块连续的区域里面，避免内存碎片，这种布局被称为embstr编码方式。</p>
<p>当然，当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。</p>
<p><img src="https://static001.geekbang.org/resource/image/ce/e3/ce83d1346c9642fdbbf5ffbe701bfbe3.jpg?wh=3072*1938" alt="img"></p>
<p>redis会用一个全局哈希表来保存所有键值对，哈希表的每一项是一个dictEntry的结构体，用来指向一个键值对，其中用三个8字节的指针，分别指向key，value，next，共24字节。</p>
<p><img src="https://static001.geekbang.org/resource/image/b6/e7/b6cbc5161388fdf4c9b49f3802ef53e7.jpg?wh=2219*1371" alt="img"></p>
<p>，但事情还没有完，Redis的内存分配库jemalloc，它并不是申请多大的空间就给多大的空间， 而是会比你申请的空间多分配到比这个数大的最近的2的次幂，这样可以减少频繁的分配空间。</p>
<p>比如申请六个字节，就分配8个字节，24个字节就分配32个字节。</p>
<p>这些各种加起来，导致string类型空间消耗大起来了。</p>
<h4 id="用什么数据结构可以节省内存"><a href="#用什么数据结构可以节省内存" class="headerlink" title="用什么数据结构可以节省内存"></a>用什么数据结构可以节省内存</h4><p>压缩列表可以</p>
<p>压缩列表的构成。表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。</p>
<p><img src="https://static001.geekbang.org/resource/image/f6/9f/f6d4df5f7d6e80de29e2c6446b02429f.jpg?wh=3457*972" alt="img"></p>
<p>压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。</p>
<p>pre：1或者5字节</p>
<p>encoding：1字节</p>
<p>len：4字节</p>
<p>这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。</p>
<p>Redis 基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。</p>
<h4 id="如何用集合类型保存单值的键值对"><a href="#如何用集合类型保存单值的键值对" class="headerlink" title="如何用集合类型保存单值的键值对"></a>如何用集合类型保存单值的键值对</h4><p>在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。</p>
<p>以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value。</p>
<p>Redis Hash 类型的两种底层实现结构，分别是压缩列表和哈希表。</p>
<p>那么什么时候用压缩列表，什么时候用哈希表呢</p>
<p>其实，Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了。</p>
<p>这两个阈值分别对应以下两个配置项：</p>
<p>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</p>
<p>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</p>
<p>一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。</p>
<p>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。</p>
<h3 id="redis可以做消息队列吗"><a href="#redis可以做消息队列吗" class="headerlink" title="redis可以做消息队列吗"></a>redis可以做消息队列吗</h3><p>这个问题隐含着两个问题：</p>
<p>消息队列的消息存取需求是什么</p>
<p>redis如何实现消息队列的消息存取需求</p>
<h4 id="消息队列的消息存取需求"><a href="#消息队列的消息存取需求" class="headerlink" title="消息队列的消息存取需求"></a>消息队列的消息存取需求</h4><p>在分布式系统中，当两个组件要基于消息队列进行通信的时候，一个组件会被要处理的请求放入消息队列中，自己就可以执行其他操作了，远端的另一个组件从队列中把消息队列取出来，再在本地进行处理</p>
<p>假设组件 1 需要对采集到的数据进行求和计算，并写入数据库，但是，消息到达的速度很快，组件 1 没有办法及时地既做采集，又做计算，并且写入数据库。所以，我们可以使用基于消息队列的通信，让组件 1 把数据 x 和 y 保存为 JSON 格式的消息，再发到消息队列，这样它就可以继续接收新的数据了。组件 2 则异步地从消息队列中把数据读取出来，在服务器 2 上进行求和计算后，再写入数据库。这个过程如下图所示：</p>
<p><img src="https://static001.geekbang.org/resource/image/d7/bc/d79d46ec4aa22bf46fde3ae1a99fc2bc.jpg?wh=3000*1459" alt="img"></p>
<p>我们一般把消息队列中发送消息的组件称为生产者（例子中的组件 1），把接收消息的组件称为消费者</p>
<p>在使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理。这样一来，即使生产者发送消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势。</p>
<h5 id="消息保序"><a href="#消息保序" class="headerlink" title="消息保序"></a>消息保序</h5><p>虽然消费者的信息是异步处理的，但是消息仍然需药按照生产者发送消息的顺序来处理消息，避免后发送的信息被先处理了</p>
<h5 id="重复消息处理"><a href="#重复消息处理" class="headerlink" title="重复消息处理"></a>重复消息处理</h5><p>消费者从消息队列读取信息时，有时会因为网络堵塞导致消息重传，此时如果消费者重复执行了相同的消息，如果消息是修改数据，就会导致数据出错。</p>
<h5 id="消息可靠性保证"><a href="#消息可靠性保证" class="headerlink" title="消息可靠性保证"></a>消息可靠性保证</h5><p>消费者在处理消息的时候，可能会出现故障或者宕机导致消息没处理的情况。也就是说，当消费者重启时，需要保证重新从消息队列里面读取信息再次处理。</p>
<h4 id="基于List的消息队列解决方案"><a href="#基于List的消息队列解决方案" class="headerlink" title="基于List的消息队列解决方案"></a>基于List的消息队列解决方案</h4><p>List本身是先进先出的顺序对数据进行存取，所以满足消息保序的需求。</p>
<p>不过，在生产者在写入数据时，list不会主动通知消费者有新消息写入了，如果消费者要处理消息，只能一直不停调用RPOP命令，带来了性能损失，为了解决这个问题，redis提供了阻塞形式的BRPOP，客户端在没有读到队列数据时，自动阻塞，知道队列有新数据写入队列，再开始读取新数据。</p>
<p>为了解决重复消息处理的问题，消息队列给每个消息提供全局ID，并且把处理过的ID记录下来</p>
<p>为了解决消息处理可靠性的问题，redis在消费者读取了消息后，会把这个消息存入另一个list里面去，这样如果在读取时候消费者挂了，重启后可以去备份里面读取消息处理。</p>
<p>问题出现了：生产者发送数据的数据太快了，但是消费者处理数据的速度太慢，会导致大量数据堆积在list中，给redis的内存带来很大的压力。</p>
<p>这个时候，我们希望启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。</p>
<p>因此我们引入了Stream</p>
<h4 id="基于Streams的消息队列的解决方案"><a href="#基于Streams的消息队列的解决方案" class="headerlink" title="基于Streams的消息队列的解决方案"></a>基于Streams的消息队列的解决方案</h4><p>Streams是redis专门为消息队列设计的数据类型</p>
<h5 id="XADD"><a href="#XADD" class="headerlink" title="XADD"></a>XADD</h5><p>XADD 命令可以往消息队列中插入新消息，消息的格式是键 - 值对形式。对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。</p>
<h5 id="XREAD"><a href="#XREAD" class="headerlink" title="XREAD"></a>XREAD</h5><p>XREAD 在读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取。另外，消费者也可以在调用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。当消息队列中没有消息时，一旦设置了 block 配置项，XREAD 就会阻塞，阻塞的时长可以在 block 配置项进行设置。</p>
<h5 id="XGROUP"><a href="#XGROUP" class="headerlink" title="XGROUP"></a>XGROUP</h5><p>Streams 本身可以使用 XGROUP 创建消费组，创建消费组之后，Streams 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。</p>
<p>使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。</p>
<p>为了保障消费者宕机后，仍然可以处理读取为处理的数据。</p>
<p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。</p>
<h3 id="redis的异步机制"><a href="#redis的异步机制" class="headerlink" title="redis的异步机制"></a>redis的异步机制</h3><h4 id="redis实例的阻塞点"><a href="#redis实例的阻塞点" class="headerlink" title="redis实例的阻塞点"></a>redis实例的阻塞点</h4><ol>
<li>集合全量查询和聚合操作</li>
<li>bigkey删除</li>
<li>清空数据库</li>
<li>AOF日志同步写</li>
<li>从库加载RDB文件</li>
</ol>
<h4 id="可以异步执行的阻塞点"><a href="#可以异步执行的阻塞点" class="headerlink" title="可以异步执行的阻塞点"></a>可以异步执行的阻塞点</h4><ol>
<li>bigkey删除</li>
<li>清空数据库</li>
<li>AOF文件同步写</li>
</ol>
<p>首先，什么是异步，所谓的异步线程机制，就是指，Redis 会启动一些子线程，然后把一些任务交给这些子线程，让它们在后台完成，而不再由主线程来执行这些任务。使用异步线程机制执行操作，可以避免阻塞主线程。</p>
<p>那么判断一个操作能不能异步执行的关键点是什么呢，看它是不是redis主线程关键路径上的操作。这就是说，客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作。</p>
<h4 id="异步的子线程机制"><a href="#异步的子线程机制" class="headerlink" title="异步的子线程机制"></a>异步的子线程机制</h4><p>redis主线程启动后，会使用操作系统的函数创造三个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。</p>
<p>主线程通过一个链表形式的任务列表和子线程交互，当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</p>
<h3 id="CPU架构对Redis性能的影响"><a href="#CPU架构对Redis性能的影响" class="headerlink" title="CPU架构对Redis性能的影响"></a>CPU架构对Redis性能的影响</h3><h4 id="主流的CPU架构"><a href="#主流的CPU架构" class="headerlink" title="主流的CPU架构"></a>主流的CPU架构</h4><p>一个cpu处理器有多个运行核心，每个运行核心称为一个物理核，每个物理核有自己的私有缓存L1，和私有的二级缓存L2。</p>
<p>什么是私有缓存，就是只有当前这个物理核访问，其他核心不能访问。</p>
<p>因为每个L1，L2是物理核私有的，所以它的存取速度非常快，数据保存在这里，就能高速的存取。</p>
<p>但是L1，L2受限于技术，空间并不大，因此不同的物理核之间又共享了一个L3，L3空间要大很多。</p>
<p>另外，每个物理核，还会运行两个超线程，也叫做逻辑核。同一个物理核的逻辑核会共享L1，L2缓存。</p>
<p><img src="https://static001.geekbang.org/resource/image/d9/09/d9689a38cbe67c3008d8ba99663c2f09.jpg?wh=3065*1633" alt="img"></p>
<p>在主流cpu服务器上，一个服务器会有多个CPU处理器，也叫CPU Socket。</p>
<p><img src="https://static001.geekbang.org/resource/image/5c/3d/5ceb2ab6f61c064284c8f8811431bc3d.jpg?wh=3000*1252" alt="img"></p>
<p>但是在多CPU架构上，会出现一个问题，那就是如果应用程序在socket 1上面运行了一段时间，并且把数据存储到了内存中，然后它被调度到了socket 2上面运行，这个时候它想要访问当时存到socket 1下面内存的数据时候，这个操作会比直接访问和socket 直接相连的内存要慢。</p>
<p>在多 CPU 架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构，也就是NUMA 架构</p>
<h4 id="CPU多核对性能的影响"><a href="#CPU多核对性能的影响" class="headerlink" title="CPU多核对性能的影响"></a>CPU多核对性能的影响</h4><p>CPU多核，如果应用程序频繁的被不同核心所运行， 那么就会降低效率，因为这会导致频繁地上下文切换，因此，我们应该把一个redis实例和一个核心绑定，这样可以提升redis的性能，用taskset来绑定。</p>
<h4 id="如何避免绑核后的线程竞争"><a href="#如何避免绑核后的线程竞争" class="headerlink" title="如何避免绑核后的线程竞争"></a>如何避免绑核后的线程竞争</h4><p>Redis除了主线程外，还有子线程需要工作，所以如果绑在一个核心上就会出现多个线程竞争的情况，会导致主线程阻塞。</p>
<p>为了避免这个情况，有两种方法</p>
<p>方案一：一个 Redis 实例对应绑一个物理核</p>
<p>这样可以充分利用物理核的两个逻辑核，因为有两个所以可以减少线程竞争的情况</p>
<p>方案二：优化 Redis 源码</p>
<p>这个方案就是通过修改 Redis 源码，把子进程和后台线程绑到不同的 CPU 核上。</p>
<h3 id="Redis变慢了"><a href="#Redis变慢了" class="headerlink" title="Redis变慢了"></a>Redis变慢了</h3><h4 id="Redis自身操作特性的影响"><a href="#Redis自身操作特性的影响" class="headerlink" title="Redis自身操作特性的影响"></a>Redis自身操作特性的影响</h4><h5 id="1-慢查询命令"><a href="#1-慢查询命令" class="headerlink" title="1.慢查询命令"></a>1.慢查询命令</h5><p>慢查询命令，就是在redis上执行速度比较慢的命令，会导致redis延迟增加。</p>
<p>解决方法：尽量避免使用慢查询命令，替换成更高效的方法。当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。</p>
<h5 id="2-过期KEY操作"><a href="#2-过期KEY操作" class="headerlink" title="2.过期KEY操作"></a>2.过期KEY操作</h5><p>首先需要知道，redis自己本身就有过期key自动删除机制。</p>
<p>机制的算法如下：</p>
<ol>
<li>采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；</li>
<li>如果超过25%的key过期了，则重复删除的操作，知道过期key的比率降到25%一下。</li>
</ol>
<p>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 是 Redis 的一个参数，默认是 20，那么，一秒内基本有 200 个过期 key 会被删除。</p>
<p>但是如果触发了算法的第二条，redis就会一直删除来释放空间，但是删除操作本身是阻塞的（4.0后可以异步执行），会导致redis变慢。</p>
<p>解决方法：避免使用带有相同时间参数的key命令，只会导致它们会一起过期。</p>
<h4 id="文件系统对redis的影响"><a href="#文件系统对redis的影响" class="headerlink" title="文件系统对redis的影响"></a>文件系统对redis的影响</h4><h5 id=""><a href="#" class="headerlink" title=""></a></h5><p>redis采用aof日志模式的时候，提供了三种写回策略，no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是 write 和 fsync。</p>
<p>write只要把日志记录到缓冲区就返回了，并不需要等日志实际写到磁盘，而 fsync 需要把日志记录写回到磁盘后才能返回，时间较长。</p>
<p><img src="https://static001.geekbang.org/resource/image/9f/a4/9f1316094001ca64c8dfca37c2c49ea4.jpg?wh=2720*598" alt="img"></p>
<p>其中everysec策略时，redis使用后台子进程异步完成fsync操作。</p>
<p>但always不行，always使用的主线程来完成。</p>
<p>除此之外，另外，在使用 AOF 日志时，为了避免日志文件不断增大，Redis 会执行 AOF 重写，生成体量缩小的新的 AOF 日志文件。AOF 重写本身需要的时间很长，也容易阻塞 Redis 主线程，所以，Redis 使用子进程来进行 AOF 重写。</p>
<p>但是，AOF重写会进行大量的磁盘IO操作，同时，fsync又需要等到数据写到磁盘才能返回，当AOF重写压力大的时候，就会导致fsync阻塞，虽然它在子线程进行，但是主线程会监视子线程，如果子线程阻塞，主线程发现上一次给子线程的fsync没有执行完，那么它就会阻塞，性能变慢。</p>
<p><img src="https://static001.geekbang.org/resource/image/2a/a6/2a47b3f6fd7beaf466a675777ebd28a6.jpg?wh=3000*1557" alt="img"></p>
<h4 id="操作系统对redis的影响"><a href="#操作系统对redis的影响" class="headerlink" title="操作系统对redis的影响"></a>操作系统对redis的影响</h4><h5 id="1-swap"><a href="#1-swap" class="headerlink" title="1.swap"></a>1.swap</h5><p>内存swap是操作系统将内存数据和磁盘数据来回换入换出的机制，涉及到磁盘的读写。所以，一旦触发 swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。</p>
<p>而且，和我刚才说的 AOF 日志文件读写使用 fsync 线程不同，swap 触发后影响的是 Redis 主 IO 线程，这会极大地增加 Redis 的响应时间。</p>
<p>通常，触发 swap 的原因主要是物理机器内存不足</p>
<p>解决思路：增加机器的内存或者使用 Redis 集群。</p>
<h5 id="2-内存大页"><a href="#2-内存大页" class="headerlink" title="2.内存大页"></a>2.内存大页</h5><p>redis为了保证数据可靠性，需要对数据进行持久化操作，如果此时客户端对redis进行写入数据，数据涉及到正在持久化的数据，那么redis就会曹勇写时复制机制，会对数据页进行拷贝，如果采用内存大页，可能100kb的数据进行修改，也需要复制2MB的大页，导致性能变慢。</p>
<p>解决方法：关闭内存大页。</p>
<h3 id="旁路缓存，redis如何工作的"><a href="#旁路缓存，redis如何工作的" class="headerlink" title="旁路缓存，redis如何工作的"></a>旁路缓存，redis如何工作的</h3><h4 id="缓存的特征"><a href="#缓存的特征" class="headerlink" title="缓存的特征"></a>缓存的特征</h4><p>首先，一个系统不同层的访问速度不一样，我们才需要缓存。</p>
<p>这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度。例如：</p>
<p><img src="https://static001.geekbang.org/resource/image/7d/44/7dyycf727f9396eb9788644474855a44.jpg?wh=2156*1239" alt="img"></p>
<p>计算机系统中，默认有两种缓存：</p>
<p>CPU 里面的末级缓存，即 LLC，用来缓存内存中的数据，避免每次从内存中存取数据；内</p>
<p>存中的高速页缓存，即 page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。</p>
<p>缓存两大特征：</p>
<p>在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。</p>
<p>缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。</p>
<h4 id="redis缓存处理请求的方式"><a href="#redis缓存处理请求的方式" class="headerlink" title="redis缓存处理请求的方式"></a>redis缓存处理请求的方式</h4><h5 id="缓存命中："><a href="#缓存命中：" class="headerlink" title="缓存命中："></a>缓存命中：</h5><p>Redis 中有相应数据，就直接读取 Redis，性能非常快。</p>
<h5 id="缓存缺失："><a href="#缓存缺失：" class="headerlink" title="缓存缺失："></a>缓存缺失：</h5><p>Redis 中没有保存相应数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失，为了让后续请求能从缓存中读取到数据，我们需要把缺失的数据写入 Redis，这个过程叫作缓存更新。</p>
<p><img src="https://static001.geekbang.org/resource/image/6b/3d/6b0b489ec0c1c5049c8df84d77fa243d.jpg?wh=2750*1631" alt="img"></p>
<h4 id="redis缓存类型"><a href="#redis缓存类型" class="headerlink" title="redis缓存类型"></a>redis缓存类型</h4><h5 id="只读缓存"><a href="#只读缓存" class="headerlink" title="只读缓存"></a>只读缓存</h5><p>当redis用作只读缓存时，读请求会先在缓存中查看数据是否存在。而写请求则全部交给数据库，在数据库中增删改，对于删除的数据来说，如果redis已经缓存了相应的数据，应用需要把这些缓存的数据删除，redis中就没有这些数据了。</p>
<p>只读缓存好处是，保证了最新的数据在数据库里面，数据库有可靠性保障，数据更安全。</p>
<h5 id="读写缓存"><a href="#读写缓存" class="headerlink" title="读写缓存"></a>读写缓存</h5><p>对于读写缓存来说，除了读请求会发送到缓存进行处理（直接在缓存中查询数据是否存在)，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。</p>
<p>但是，和只读缓存不一样的是，在使用读写缓存时，最新的数据是在 Redis 中，而 Redis 是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新数据可能会丢失，给应用业务带来风险。</p>
<p>因此它提供了两个策略</p>
<ol>
<li>同步直写，写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。</li>
<li>异步写回，所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。</li>
</ol>
<h3 id="redis缓存淘汰策略"><a href="#redis缓存淘汰策略" class="headerlink" title="redis缓存淘汰策略"></a>redis缓存淘汰策略</h3><h4 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h4><p>Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略。</p>
<p>我们可以按照是否会进行数据淘汰把它们分成两类：</p>
<p>不进行数据淘汰的策略，只有 noeviction 这一种。</p>
<p>会进行淘汰的 7 种其他策略。</p>
<p>会进行淘汰的 7 种策略，我们可以再进一步根据淘汰候选数据集的范围把它们分成两类：</p>
<p>在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种。</p>
<p>在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。</p>
<p><img src="https://static001.geekbang.org/resource/image/04/f6/04bdd13b760016ec3b30f4b02e133df6.jpg?wh=1757*765" alt="img"></p>
<p>noevction：它不进行淘汰，满了后就不再提供服务。</p>
<p>volatile-random、volatile-ttl、volatile-lru 和 volatile-lfu：它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。也正因为此，即使缓存没有写满，这些数据如果过期了，也会被删除。</p>
<p>allkeys-lru、allkeys-random、allkeys-lfu：淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。</p>
<h4 id="LRU算法"><a href="#LRU算法" class="headerlink" title="LRU算法"></a>LRU算法</h4><p>LRU 算法的全称是 Least Recently Used，从名字上就可以看出，这是按照最近最少使用的原则来筛选数据，最不常用的数据会被筛选出来，而最近频繁使用的数据会留在缓存中。</p>
<p>LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。</p>
<p><img src="https://static001.geekbang.org/resource/image/02/y5/0201f85c84203300ae4085c60e955yy5.jpg?wh=1702*1678" alt="img"></p>
<p>如果有一个新数据 15 要被写入缓存，但此时已经没有缓存空间了，也就是链表没有空余位置了，</p>
<p>那么，LRU 算法做两件事：数据 15 是刚被访问的，所以它会被放到 MRU 端；算法把 LRU 端的数据 5 从缓存中删除，相应的链表中就没有数据 5 的记录了。</p>
<p>不过，LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会带来额外的空间开销。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。</p>
<p>Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。</p>
<p>具体来说，Redis 默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构 RedisObject 中的 lru 字段记录）。然后，Redis 在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。</p>
<p>当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。</p>
<h4 id="如何处理被淘汰的数据"><a href="#如何处理被淘汰的数据" class="headerlink" title="如何处理被淘汰的数据"></a>如何处理被淘汰的数据</h4><p>一旦被淘汰的数据选定后，如果这个数据是干净数据，那么我们就直接删除；如果这个数据是脏数据，我们需要把它写回数据库</p>
<p>干净数据和脏数据的区别就在于，和最初从后端数据库里读取时的值相比，有没有被修改过。</p>
<p>干净数据一直没有被修改，所以后端数据库里的数据也是最新值。在替换时，它可以被直接删除。</p>
<p>而脏数据就是曾经被修改过的，已经和后端数据库中保存的数据不一致了。此时，如果不把脏数据写回到数据库中，这个数据的最新值就丢失了，就会影响应用的正常使用。</p>
<h3 id="缓存异常"><a href="#缓存异常" class="headerlink" title="缓存异常"></a>缓存异常</h3><h4 id="缓存数据和数据库不一致"><a href="#缓存数据和数据库不一致" class="headerlink" title="缓存数据和数据库不一致"></a>缓存数据和数据库不一致</h4><p>对于读写缓存，可以采用同步写回策略</p>
<p>对于只读缓存</p>
<p><img src="https://static001.geekbang.org/resource/image/11/6f/11ae5e620c63de76448bc658fe6a496f.jpg?wh=2889*1355" alt="img"></p>
<p>其中先删除缓存值，再更新数据库的操作中，重试数据库更新是用消息队列来实现</p>
<p>其中先删除缓存值，再更新数据库的操作中，延迟双删是指执行删除的线程1在更新数据库后，sleep一段时间，让来读取这个数据的线程2读数据，发现缓存没有，然后从数据库中找到值更新过去，由于是并发执行的，这里线程2读到的可能是旧值，因此需要删除这个存到缓存的数据，然后sleep醒过来的线程1再进行删除线程2更新的缓存。这之后的线程就发现缓存中没有，去数据库读到最新值了。</p>
<h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><p>缓存雪崩是指大量的应用请求无法在redis缓存中进行处理，紧接着大量请求发送给数据库层，数据库压力激增。</p>
<p>原因：</p>
<ol>
<li>缓存中有大量数据同时过期，导致大量数据无法得到处理</li>
</ol>
<p>​	解决方案：</p>
<p>​			1.避免给大量数据设置相同的过期时间，就算是业务要求有些数据时间相同，可以使用EXPIRE给每个数据				设置过期时间的时候，加上一个较小的随机数。</p>
<p>​			2. 服务降级，就是当业务访问的是非核心数据时，就暂停从缓存中查询这些数据，而是直接返回预定义信				息，空值，或错误信息。当业务访问的是核心数据时，就仍然允许查询缓存，如果需要访问数据库，也				允许</p>
<pre><code>2. redis缓存实例发送故障宕机了，无法处理请求，大量请求堆积到数据库层
</code></pre>
<p>​	解决方法：</p>
<p>​				1.在业务系统中实现服务熔断，即业务应用调用缓存接口时，缓存客户端并不把请求发送给redis缓存实例，而是直接返回，等到redis缓存实例重启后，再运行请求发送到缓存实例。</p>
<p>​				2.请求限流，在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</p>
<p>​				3.构建redis高可用缓存集群，主节点挂掉后，从节点替换主节点继续提供服务。</p>
<h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><p>缓存击穿就是大量的热点数据同时过期，导致大量请求访问到数据层</p>
<p>解决方法：对于访问特别频繁的数据可以不设置过期时间。或者提前预热，把热点数据重新存入，设置好过期时间。</p>
<h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p>缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。</p>
<p>第一种方案：缓存空值或缺省值</p>
<p>第二种方案：使用布隆过滤器快速判断数据是否存在，避免从数据库查询数据。</p>
<p>布隆过滤器怎么工作的呢？</p>
<p>布隆过滤器由一个初值为0的bit数组和N个哈希函数组成，可以用来快速判断某个数据是否存在。</p>
<p>如何标记一个数存在：</p>
<ul>
<li>首先，使用N个哈希函数对数据求哈希值，得到N个哈希值</li>
<li>把这N个哈希值对bit数组的长度取模，得到哈希值在数组中的对应位置</li>
<li>最后，把对应位置的bit位设置为1。</li>
</ul>
<p>当需要查询这个数据时，我们就执行刚刚说的计算过程，先得到这个数据在bit数组中对应的N个位置，紧接着查看这N个位置的bit值，有一个不为1就说明数据库中不存在这个数据。</p>
<p><img src="https://static001.geekbang.org/resource/image/98/68/98f7d32499e4386b40aebc3622aa7268.jpg?wh=2953*1342" alt="img"></p>
<p>第三种方案，在请求入口的前端进行请求检测。</p>
<h4 id="缓存污染"><a href="#缓存污染" class="headerlink" title="缓存污染"></a>缓存污染</h4><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p>有些数据访问次数很少，被访问一次后很久都不会再被访问了，但是它们仍然占据了缓存空间，这就是缓存污染</p>
<h5 id="LFU算法"><a href="#LFU算法" class="headerlink" title="LFU算法"></a>LFU算法</h5><p>redis采用的是LFU算法，LFU算法采取的策略是，首先根据数据的访问次数来筛选，把访问次数最低的淘汰，如果数据访问次数一样，就比较数据的访问时效性，把距离上一次访问最远的淘汰。</p>
<p>实现上面，仍然和LRU算法一样，采取RedisObject的lru字段来存储数据的时间戳和访问次数</p>
<p>前16位记录时间戳，后8位记录访问次数</p>
<p>问题来了，8位只能记录到255次，这个数据太小了，很容易填满。</p>
<p>redis为了防止这种情况出现，设置了一种非线性增长的方法来增加count次数</p>
<p>那就是，数据每被访问一次，就把它和配置项相乘加一，然后取倒数，得到的值和0到1的随机数比较，如果大于随机数，就加1。</p>
<p>使用了这种计算规则后，我们可以通过设置不同的 lfu_log_factor 配置项，来控制计数器值增加的速度，避免 counter 值很快就到 255 了。</p>
<p>在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter 值的衰减机制。</p>
<p>LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。</p>
<h3 id="原子操作来实现并发"><a href="#原子操作来实现并发" class="headerlink" title="原子操作来实现并发"></a>原子操作来实现并发</h3><p>为了实现并发访问的正确性，redis提供了两种方法，加锁和原子操作，但是由于加锁会降低redis的性能，所以推荐使用原子操作的方式。</p>
<p>并发访问操作主要是对数据进行修改，分为读取，修改，写回这三步，如果不对其控制，会导致错误。</p>
<p>redis提供了两种方法避免这个问题</p>
<h4 id="单命令操作"><a href="#单命令操作" class="headerlink" title="单命令操作"></a>单命令操作</h4><p>由于redis本身是单命令操作的，命令之间是互斥的。所以我们可以把读取，修改，写回，这三个步骤变成一个命令，单命令，再加上redis的互斥，就能保障并发控制了。</p>
<p>比如INCR&#x2F;DECR</p>
<h4 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a>Lua脚本</h4><p>但是有些命令，没那么简单，需要根据实际需求去调整，这个时候我们可以采用Lua脚本的方式。Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。</p>
<h3 id="Redis实现分布式锁"><a href="#Redis实现分布式锁" class="headerlink" title="Redis实现分布式锁"></a>Redis实现分布式锁</h3><h4 id="基于单节点的分布式锁"><a href="#基于单节点的分布式锁" class="headerlink" title="基于单节点的分布式锁"></a>基于单节点的分布式锁</h4><p>使用setnx命令，这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何设置。</p>
<p>对于释放锁操作来说，我们可以在执行完业务逻辑后，使用 DEL 命令删除锁变量。</p>
<p>不过这样仍然有风险：</p>
<p>第一个风险：假如某个客户端在执行了 SETNX 命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。</p>
<p>针对这个问题，一个有效的解决方法是，给锁变量设置一个过期时间。</p>
<p>第二个风险。如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了 DEL 命令释放锁，此时，客户端 A 的锁就被误释放了。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端 A 和 C 同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。</p>
<p>给客户端加上唯一标识来解决第二个风险。</p>
<p>因为在加锁操作中，每个客户端都使用了一个唯一标识，所以在释放锁操作时，我们需要判断锁变量的值，是否等于执行释放锁操作的客户端的唯一标识</p>
<p>&#x2F;&#x2F;释放锁 比较unique_value是否相等，避免误释放<br>if redis.call(“get”,KEYS[1]) &#x3D;&#x3D; ARGV[1] then<br>    return redis.call(“del”,KEYS[1])<br>else<br>    return 0<br>end</p>
<p>为什么要用Lua脚本，因为其中包含了读取锁变量，判断值，删除锁变量这三个 操作，所以需要原子性操作。</p>
<h4 id="基于多节点的分布式锁"><a href="#基于多节点的分布式锁" class="headerlink" title="基于多节点的分布式锁"></a>基于多节点的分布式锁</h4><p>Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。</p>
<p>第一步是，客户端获取当前时间。第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作。</p>
<p>第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。</p>
<h3 id="redis的ACID"><a href="#redis的ACID" class="headerlink" title="redis的ACID"></a>redis的ACID</h3><h4 id="什么是ACID"><a href="#什么是ACID" class="headerlink" title="什么是ACID"></a>什么是ACID</h4><p>第一个是原子性：事务中的多个操作必须都完成，或者都不完成</p>
<p>第二个是一致性：数据库中的数据在事务执行前后是一致的，例如转账业务中，无论事务是否成功，转账者和收款								人的总额应该是不变的；</p>
<p>第三个是隔离性：数据库在执行一个事务的时候，其他操作无法存取正在执行事务访问的数据</p>
<p>第四个是持久性：数据库执行事务后，数据的修改要被持久化保存下来。</p>
<h4 id="Redis如何实现事务"><a href="#Redis如何实现事务" class="headerlink" title="Redis如何实现事务"></a>Redis如何实现事务</h4><p>redis用MULTI、EXEC两个命令来完成。</p>
<p>第一步，客户端使用multl开启事务</p>
<p>第二步，客户端发送命令到服务器端，这些操作就是redis本身提供的数据读写命令，这些命令虽然被传到服务器端但是不会真的被执行，而是会暂存到一个命令队列里面。</p>
<p>第三步，客户端发送EXEC，服务端真正执行事务</p>
<h4 id="Redis的事务机制能保证哪些属性"><a href="#Redis的事务机制能保证哪些属性" class="headerlink" title="Redis的事务机制能保证哪些属性"></a>Redis的事务机制能保证哪些属性</h4><h5 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h5><p>命令入队时就报错，会放弃事务执行，保证原子性</p>
<p>命令入队时未检测出来，实际执行时会报错，不能保证原子性</p>
<p>EXEC命令执行时，redis实例故障，如果开启了AOF日志，可以保证原子性</p>
<h5 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h5><p>情况1：命令入队时报错</p>
<p>事务会被放弃执行，可以保证一致性</p>
<p>情况2：命令执行时报错</p>
<p>错误命令不会被执行，正确命令会被执行，可以保证一致性</p>
<p>情况3：EXEC命令时redis实例宕机</p>
<p>如果没有开启AOF和RDB，那么宕机后，数据就没有了，可以保证一致性</p>
<p>如果开启了RDB，事务执行时是不会进行RDB快照的，所以事务命令不会保存到RDB中，可以保证一致性</p>
<p>如果使用了AOF，而事务操作还没有被记录到 AOF 日志时，实例就发生了故障，那么，使用 AOF 日志恢复的数据库数据是一致的。如果只有部分操作被记录到了 AOF 日志，我们可以使用 redis-check-aof 清除事务中已经完成的操作，数据库恢复后也是一致的。</p>
<h5 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h5><p>分为在EXEC执行前和执行后</p>
<p>执行前：需要用WATCH机制来保障，</p>
<p>执行后：可以保证</p>
<p>WATCH机制：在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC命令执行时，WATCH机制会检查监控的键是否被其他客户端修改，如果被修改了，则放弃事务的执行来保障隔离性。</p>
<p><img src="https://static001.geekbang.org/resource/image/4f/73/4f8589410f77df16311dd29131676373.jpg?wh=3000*1921" alt="img"></p>
<h5 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h5><p>如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证。</p>
<p>如果 Redis 使用了 RDB 模式，那么，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。</p>
<p>如果 Redis 采用了 AOF 模式，因为 AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。</p>
<p>所以，不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。</p>
<h3 id="Redis对秒杀场景的支持"><a href="#Redis对秒杀场景的支持" class="headerlink" title="Redis对秒杀场景的支持"></a>Redis对秒杀场景的支持</h3><h4 id="秒杀场景对系统的要求"><a href="#秒杀场景对系统的要求" class="headerlink" title="秒杀场景对系统的要求"></a>秒杀场景对系统的要求</h4><p>一个是并发量高</p>
<p>一个是读多写少，快速处理大量的读操作。</p>
<h4 id="redis在秒杀的哪些环节发挥"><a href="#redis在秒杀的哪些环节发挥" class="headerlink" title="redis在秒杀的哪些环节发挥"></a>redis在秒杀的哪些环节发挥</h4><p>第一阶段是秒杀活动前。在这个阶段，用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量把商品详情页的页面元素静态化，然后使用 CDN 或是浏览器把这些静态化的元素缓存起来。不需要redis</p>
<p>第二阶段是秒杀活动开始。</p>
<p>此时，大量用户点击商品详情页上的秒杀按钮，会产生大量的并发请求查询库存。一旦某个请求查询到有库存，紧接着系统就会进行库存扣减。然后，系统会生成实际订单，并进行后续处理，例如订单支付和物流服务。如果请求查不到库存，就会返回。用户通常会继续点击秒杀按钮，继续查询库存。</p>
<p>简单来说，这个阶段的操作就是三个：库存查验、库存扣减和订单处理。因为每个秒杀请求都会查询库存，而请求只有查到有库存余量后，后续的库存扣减和订单处理才会被执行。所以，这个阶段中最大的并发压力都在库存查验操作上。</p>
<p>为了支撑大量高并发的库存查验请求，我们需要在这个环节使用 Redis 保存库存量，这样一来，请求可以直接从 Redis 中读取库存并进行查验。</p>
<p>那么，库存扣减和订单处理是否都可以交给后端的数据库来执行呢?</p>
<p>其实，订单处理可以在数据库中执行，但库存扣减操作，不能交给后端数据库处理。</p>
<p>为什么用数据库呢？</p>
<p>订单处理会涉及支付、商品出库、物流等多个关联操作，这些操作本身涉及数据库中的多张数据表，要保证处理的事务性，需要在数据库中完成。</p>
<p>那为啥库存扣减操作不能在数据库执行呢？这是因为，一旦请求查到有库存，就意味着发送该请求的用户获得了商品的购买资格，用户就会下单了。同时，商品的库存余量也需要减少一个。如果我们把库存扣减的操作放到数据库执行，会带来两个问题。</p>
<ol>
<li>额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。</li>
<li>下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。</li>
</ol>
<p><img src="https://static001.geekbang.org/resource/image/7c/1b/7c3e5def912d7c8c45bca00f955d751b.jpg?wh=2176*1582" alt="img"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zjpzytzjp.github.io/2023/08/10/redis/" data-id="cll4s246c0001msuxe7zw4i5y" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/10/hello-world/" class="article-date">
  <time class="dt-published" datetime="2023-08-10T02:41:13.051Z" itemprop="datePublished">2023-08-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/08/10/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zjpzytzjp.github.io/2023/08/10/hello-world/" data-id="cll4s245s0000msux8pag8aif" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/08/10/redis/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/08/10/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>